{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6U9hANiOVOsyWlNd5ZN1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/CNN/DCGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwdYFEwDnpVQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, datasets, optimizers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spyx2AUSn1j4"
      },
      "source": [
        "class DCGAN():\n",
        "  def __init__(self, rows, cols, channels, z=10):\n",
        "    #input shape\n",
        "    self.img_rows = rows\n",
        "    self.img_cols = cols\n",
        "    self.channels = channels\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "    self.latent_dim = z\n",
        "\n",
        "    optimizer = optimizers.Adam(0.0002, 0.5)\n",
        "    \n",
        "    #build and compile the discriminator\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    #build the generator\n",
        "    self.generator = self.build_generator()\n",
        "\n",
        "    #the generator takes noise as input and generates imgs\n",
        "    z = tf.kears.Input(shape=(self.latent_dim,))\n",
        "    img = self.generator(z)\n",
        "\n",
        "    #생성기 판별기 결합\n",
        "    self.combined = models.Model(z, valid)\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "  def build_generator(self):\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "    model.add(layers.Reshape((7, 7, 128)))\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.Activation(\"relu\"))\n",
        "    model.add(layers.Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "    model.add(layers.Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = tf.keras.Input(shape=(self.latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(layers.ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(layers.BatchNormalization(momentum=0.8))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = tf.keras.Input(shape=self.img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}