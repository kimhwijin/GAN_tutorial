{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_translate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1f4g_ihbjfN7sTtTCT4gX8w13s3DK76xJ",
      "authorship_tag": "ABX9TyMj+TescpMv0lLoJ4XXLoPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/RNN/seq2seq_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuToWArdQcY4"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import unicodedata\n",
        "import zipfile\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXjiazl8Q3fD"
      },
      "source": [
        "def preprocessing_sentence(sent):\n",
        "    sent = \"\".join([c for c in unicodedata.normalize(\"NFD\", sent) if unicodedata.category(c) != \"Mn\"])\n",
        "    #문자열 앞에 r 이붙으면 그대로 반환 r'abcd\\n' = abcd\\n\n",
        "    sent = re.sub(r\"([!.?])\", r\" \\1\", sent)\n",
        "    #알파벳 또는 ! ? 제외하고 공백으로 치환\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "    #공백문자를 띄어쓰기 한칸으로 변경\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    sent = sent.lower()\n",
        "    return sent\n",
        "\n",
        "def download_and_read(url, num_sent_pairs=30000):\n",
        "\n",
        "    local_file = url.split('/')[-1]\n",
        "    drive_path = \"drive/MyDrive/Datasets/anki-eng-frg\"\n",
        "    data_path = os.path.join(drive_path, local_file)\n",
        "    if not os.path.isfile(data_path):\n",
        "        os.system('wget -O {:s} -P {:s} {:s}'.format(local_file, drive_path, url))\n",
        "        with zipfile.ZipFile(data_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(data_path)\n",
        "    file_path = os.path.join(drive_path, 'fra.txt')\n",
        "    en_sents, fr_sents_in, fr_sents_out = [], [], []\n",
        "\n",
        "    with open(file_path, 'r') as fin:\n",
        "        for i , line in enumerate(fin):\n",
        "            en_sent, fr_sent, _ = line.strip().split('\\t')\n",
        "            en_sent = [w for w in preprocessing_sentence(en_sent).split()]\n",
        "            fr_sent = preprocessing_sentence(fr_sent)\n",
        "            fr_sent_in = [w for w in (\"BOS\" + fr_sent).split()]\n",
        "            fr_sent_out = [w for w in (fr_sent + \"EOS\").split()]\n",
        "            en_sents.append(en_sent)\n",
        "            fr_sents_in.append(fr_sent_in)\n",
        "            fr_sents_out.append(fr_sent_out)\n",
        "            if i >= num_sent_pairs - 1:\n",
        "                break\n",
        "    return en_sents, fr_sents_in, fr_sents_out\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BN8aEd_a3j2"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_timestemps, encoder_dim, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "        self.encoder_dim = encoder_dim\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=num_timestemps)\n",
        "        self.rnn = tf.keras.layers.GRU(self.encoder_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, x, state):\n",
        "        x = self.embedding(x)\n",
        "        x, state = self.rnn(x, initial_state=state)\n",
        "        return x, state\n",
        "    def init_state(self, batch_size):\n",
        "        return tf.zeros((batch_size, self.encoder_dim))\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_timestemps, decoder_dim, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.decoder_dim = decoder_dim\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, decoder_dim, input_length=num_timestemps)\n",
        "        self.rnn = tf.keras.layers.GRU(decoder_dim, return_sequences=True, return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    def call(self, x, state):\n",
        "        x = self.embedding(x)\n",
        "        x, state = self.rnn(x, state)\n",
        "        x = self.dense(x)\n",
        "        return x, state"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgJgq7a_aAwU"
      },
      "source": [
        "#하이퍼 파라미터\n",
        "NUM_SENT_PAIRS = 30000\n",
        "EMBEDDING_DIM = 256\n",
        "ENCODER_DIM, DECODER_DIM = 1024, 1024\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "#문장 데이터\n",
        "sents_en, sents_fr_in, sents_fr_out = download_and_read('https://www.manythings.org/anki/fra-eng.zip', NUM_SENT_PAIRS)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieSwi1kdTOW6",
        "outputId": "0305a972-21d5-45b6-d732-9f807d7a89d5"
      },
      "source": [
        "#토크나이저\n",
        "tokenizer_en = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en)\n",
        "data_en = tokenizer_en.texts_to_sequences(sents_en)\n",
        "#뒤쪽 빈 부분을 채워줌\n",
        "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en, padding='post')\n",
        "\n",
        "#데이터 및 토크나이저 설정\n",
        "tokenizer_fr = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fr.fit_on_texts(sents_fr_in)\n",
        "tokenizer_fr.fit_on_texts(sents_fr_out)\n",
        "data_fr_in = tokenizer_fr.texts_to_sequences(sents_fr_in)\n",
        "data_fr_out = tokenizer_fr.texts_to_sequences(sents_fr_out)\n",
        "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in, padding='post')\n",
        "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out, padding='post')\n",
        "\n",
        "#단어 개수\n",
        "vocab_size_en = len(tokenizer_en.word_index)\n",
        "vocab_size_fr = len(tokenizer_fr.word_index)\n",
        "word2idx_en = tokenizer_en.word_index\n",
        "idx2word_en = {v: k for k , v in word2idx_en.items()}\n",
        "word2idx_fr = tokenizer_fr.word_index\n",
        "idx2word_fr = {v: k for k , v in word2idx_fr.items()}\n",
        "print(\"단어 사이즈 (en) : {:d}, (fr) : {:d}\".format(vocab_size_en, vocab_size_fr))\n",
        "maxlen_en = data_en.shape[1]\n",
        "maxlen_fr = data_fr_out.shape[1]\n",
        "print(\"기준 시퀀셜 길이 (en) : {:d}, (fr) : {:d}\".format(maxlen_en, maxlen_fr))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 사이즈 (en) : 4354, (fr) : 8740\n",
            "기준 시퀀셜 길이 (en) : 8, (fr) : 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtHPC2qEaKAC"
      },
      "source": [
        "#test, train dataset // 1 : 3 비율\n",
        "dataset = tf.data.Dataset.from_tensor_slices((data_en, data_fr_in, data_fr_out))\n",
        "dataset = dataset.shuffle(10000)\n",
        "test_size = NUM_SENT_PAIRS // 4\n",
        "test_dataset = dataset.take(test_size).batch(BATCH_SIZE, drop_remainder=True)\n",
        "train_dataset = dataset.skip(test_size).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6W74W8khgm-"
      },
      "source": [
        "encoder = Encoder(vocab_size_en + 1, EMBEDDING_DIM, maxlen_en, ENCODER_DIM)\n",
        "decoder = Decoder(vocab_size_fr + 1, EMBEDDING_DIM, maxlen_fr, ENCODER_DIM)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PatFnXd-h9ZI",
        "outputId": "9f7ab2d5-f8ce-42ae-e416-00a0314424c7"
      },
      "source": [
        "#shape test\n",
        "for encoder_in, decoder_in, decoder_out in train_dataset:\n",
        "    encoder_state = encoder.init_state(BATCH_SIZE)\n",
        "    encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
        "    decoder_state = encoder_state\n",
        "    decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
        "    break\n",
        "\n",
        "print(\"Encoder 입력 : \", encoder_in.shape)\n",
        "print(\"ENcoder 출력 : \", encoder_out.shape, \"state : \", encoder_state.shape)\n",
        "print(\"Decoder 입력 : \", decoder_in.shape)\n",
        "print(\"Decoder 출력 : \", decoder_out.shape, \"state : \", decoder_state.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder 입력 :  (64, 8)\n",
            "ENcoder 출력 :  (64, 8, 1024) state :  (64, 1024)\n",
            "Decoder 입력 :  (64, 15)\n",
            "Decoder 출력 :  (64, 15) state :  (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "332JZlxbix5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}