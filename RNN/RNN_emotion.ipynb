{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_emotion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12EYAkypMr19qS97q08KpTyIRO-hAEGvj",
      "authorship_tag": "ABX9TyNh8geTwCNXClp+W2e/3ded",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/RNN/RNN_emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd5fp89W79fB"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ldayNN28tVt",
        "outputId": "f535ee54-6ad5-44a2-b073-5a60437e23be"
      },
      "source": [
        "def download_and_read(url):\n",
        "  local_file = url.split('/')[-1]\n",
        "  local_file = local_file.replace(\"%20\", \" \")\n",
        "  p = tf.keras.utils.get_file(local_file, url, extract=True, cache_dir=\".\")\n",
        "  local_folder = os.path.join(\"drive/MyDrive/Datasets/UCI_ML_ES\", local_file.split('.')[0])\n",
        "  labeled_sentences = []\n",
        "  for labeled_filename in os.listdir(local_folder):\n",
        "    if labeled_filename.endswith(\"_labelled.txt\"):\n",
        "      with open(os.path.join(local_folder, labeled_filename), \"r\") as f:\n",
        "        for line in f:\n",
        "          sentence, label = line.strip().split(\"\\t\")\n",
        "          labeled_sentences.append((sentence, label))\n",
        "\n",
        "  return labeled_sentences\n",
        "labeled_sentences = download_and_read(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\"\n",
        ")\n",
        "sentences = [s for (s, l) in labeled_sentences]\n",
        "labels = [l for (s, l) in labeled_sentences]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
            "90112/84188 [================================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7faFpFQj_YXc",
        "outputId": "3fae69dc-c7b7-420a-a3fc-1be6a06c207e"
      },
      "source": [
        "#문장의 각 단어를  token으로 변환하기\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "vocab_size = len(tokenizer.word_counts)\n",
        "print(\"vocabulary size : {:d}\".format(vocab_size))\n",
        "\n",
        "word2idx = tokenizer.word_index\n",
        "idx2word = {v:k for (k, v) in word2idx.items()}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size : 5271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3EeIg90AXJU",
        "outputId": "9b2f38e6-a7d4-4979-a666-f9f58fec5cfe"
      },
      "source": [
        "#정적인 입력크기를 정하기 위해, 대부분 문장을 수용할 수 있을 만큼의 시퀀스 길이를 정한다.\n",
        "seq_lengths = np.array([len(s.split()) for s in sentences])\n",
        "print([(p, np.percentile(seq_lengths, p)) for p in [75, 80, 90, 95, 99, 100]])\n",
        "#75% : 16단어 , 80% 18단어, 99% 36단어, 최대길이 71단어."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(75, 16.0), (80, 18.0), (90, 22.0), (95, 26.0), (99, 36.0), (100, 71.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udw1f-5cBTNh"
      },
      "source": [
        "#최대 단어길이 64로 설정\n",
        "max_seqlen = 64\n",
        "\n",
        "#데이터 셋 생성\n",
        "sentences_as_ints = tokenizer.texts_to_sequences(sentences)\n",
        "#남은 부분은 0으로 채워준다.\n",
        "sentences_as_ints = tf.keras.preprocessing.sequence.pad_sequences(sentences_as_ints, maxlen=max_seqlen)\n",
        "labels_as_ints = np.array(labels, dtype=np.float32)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((sentences_as_ints, labels_as_ints))\n",
        "\n",
        "dataset = dataset.shuffle(10000)\n",
        "test_size = len(sentences) // 3\n",
        "val_size = (len(sentences) - test_size) // 10\n",
        "test_dataset = dataset.take(test_size)\n",
        "val_dataset = dataset.skip(test_size).take(val_size)\n",
        "train_dataset = dataset.skip(test_size + val_size)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahhdZBsIINDq",
        "outputId": "d9879ff0-d1be-4975-bb19-e8b857defd3d"
      },
      "source": [
        "print(train_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 64), (None,)), types: (tf.int32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHAwMscwDPjD",
        "outputId": "e8eb2760-37c2-4275-9bff-52510549b306"
      },
      "source": [
        "class SentimentAnalysisModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, max_seqlen, **kwargs):\n",
        "    super(SentimentAnalysisModel, self).__init__(**kwargs)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, max_seqlen)\n",
        "    self.bilstm = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(max_seqlen)\n",
        "    )\n",
        "    self.dense = tf.keras.layers.Dense(64, activation='relu')\n",
        "    self.out = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.bilstm(x)\n",
        "    x = self.dense(x)\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "\n",
        "model = SentimentAnalysisModel(vocab_size+1, max_seqlen)\n",
        "model.build(input_shape=(batch_size, max_seqlen))\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\", \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sentiment_analysis_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  337408    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional multiple                  66048     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  65        \n",
            "=================================================================\n",
            "Total params: 411,777\n",
            "Trainable params: 411,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF_qv-sL56Qv"
      },
      "source": [
        "data_dir = \"drive/MyDrive/Colab Notebooks/models/RNN/sentiment_analysis/\"\n",
        "logs_dir = \"drive/MyDrive/Colab Notebooks/logs/RNN/sentiment_analysis/\"\n",
        "best_model_file = os.path.join(data_dir, \"best_model.h5\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4uqC4HHEsMi",
        "outputId": "51c90586-1cb4-4c92-92db-10a3344a2a3f"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(best_model_file, save_weights_only=True, save_best_only=True)\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logs_dir)\n",
        "num_epochs = 10\n",
        "history = model.fit(train_dataset, epochs=num_epochs, \n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[checkpoint, tensorboard])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 8s 153ms/step - loss: 0.6918 - accuracy: 0.5128 - val_loss: 0.6799 - val_accuracy: 0.5600\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.6180 - accuracy: 0.7133 - val_loss: 0.4925 - val_accuracy: 0.8500\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 3s 100ms/step - loss: 0.4020 - accuracy: 0.8611 - val_loss: 0.2471 - val_accuracy: 0.9150\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 3s 99ms/step - loss: 0.2280 - accuracy: 0.9267 - val_loss: 0.1728 - val_accuracy: 0.9450\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 3s 98ms/step - loss: 0.1526 - accuracy: 0.9500 - val_loss: 0.2388 - val_accuracy: 0.9100\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 3s 101ms/step - loss: 0.1246 - accuracy: 0.9633 - val_loss: 0.0738 - val_accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 3s 102ms/step - loss: 0.0982 - accuracy: 0.9672 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 3s 103ms/step - loss: 0.0758 - accuracy: 0.9778 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 3s 104ms/step - loss: 0.0654 - accuracy: 0.9789 - val_loss: 0.0768 - val_accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 3s 100ms/step - loss: 0.0471 - accuracy: 0.9894 - val_loss: 0.0352 - val_accuracy: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3CAeuri5nwK",
        "outputId": "dc2e39dd-53d9-446a-cc0d-8ac0947a6929"
      },
      "source": [
        "best_model = SentimentAnalysisModel(vocab_size+1, max_seqlen)\n",
        "best_model.build(input_shape=(batch_size, max_seqlen))\n",
        "best_model.load_weights(best_model_file)\n",
        "best_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "test_loss, test_acc = best_model.evaluate(test_dataset)\n",
        "print(\"test loss : {:.3f}, test accuracy : {:.3f}\".format(test_loss, test_acc))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 2s 28ms/step - loss: 0.0565 - accuracy: 0.9890\n",
            "test loss : 0.057, test accuracy : 0.989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS7PGr-a60su"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}