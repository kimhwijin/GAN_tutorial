{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOM_color_mapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iSLG2Xr-IFlD3XI4vbK-bc-XpfSRhiFD",
      "authorship_tag": "ABX9TyOVVcCX3ifq/iNN0JiRggHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/UNSUPERVISED/SOM_color_mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9ggykJnGAwR"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PrCOGvzJJqO"
      },
      "source": [
        "tf.random.set_seed(11)\n",
        "np.random.seed(11)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ioXn-CsIE3D"
      },
      "source": [
        "\n",
        "class WTU(object):\n",
        "\n",
        "    def __init__(self, m, n, dim, num_iterations, eta = 0.5, sigma = None):\n",
        "        \"\"\"\n",
        "        m x n : 뉴런이 정렬될 2차원 격자\n",
        "        dim : 입력 차원\n",
        "        num_iterations : 반복 횟수\n",
        "        eta : 학습률\n",
        "        sigma : 인접 함수 반경\n",
        "        \"\"\"\n",
        "        self._m = m\n",
        "        self._n = n\n",
        "        self._neighbourhood =[]\n",
        "        self._topography = []\n",
        "        self._num_iterations = int(num_iterations)\n",
        "        self._learned = False\n",
        "        self.dim = dim\n",
        "        self.eta = eta\n",
        "\n",
        "        if sigma is None:\n",
        "            sigma = max(m, n) / 2.0 #\n",
        "        else:\n",
        "            sigma = float(sigma)\n",
        "        self.sigma = sigma\n",
        "\n",
        "        print(\"Network created with dimensions\", m, n)\n",
        "        \n",
        "        self._W = tf.random.normal([m*n, dim])\n",
        "        self._topography = np.array(list(self._neuron_location(m, n)))\n",
        "\n",
        "    def training(self, x, i):\n",
        "        m = self._m\n",
        "        n = self._n\n",
        "        d = tf.sqrt(tf.reduce_mean(tf.pow(self._W - tf.stack([x for i in range(m*n)]), 2), 1))\n",
        "        self.WTU_idx = tf.argmin(d, 0)\n",
        "\n",
        "        slice_start = tf.pad(tf.reshape(self.WTU_idx, [1]), np.array([[0,1]]))\n",
        "        self.WTU_loc = tf.reshape(tf.slice(self._topography, slice_start, [1,2]), [2])\n",
        "\n",
        "        learing_rate = 1 - i / self._num_iterations\n",
        "        _eta_new = self.eta * learing_rate\n",
        "        _sigma_new = self.sigma * learing_rate\n",
        "\n",
        "        distance_square = tf.reduce_sum(tf.pow(tf.subtract(\n",
        "            self._topography, tf.stack([self.WTU_loc for i in range(m*n)])\n",
        "        ), 2), 1)\n",
        "        neighbourhood_func = tf.exp(tf.negative(tf.math.divide(tf.cast(distance_square, \"float32\"), tf.pow(_sigma_new, 2))))\n",
        "\n",
        "        eta_into_Gamma = tf.multiply(_eta_new, neighbourhood_func)\n",
        "\n",
        "        weight_multiplier = tf.stack([tf.tile(tf.slice(\n",
        "            eta_into_Gamma, np.array([i]), np.array([1])\n",
        "        ), [self.dim]) for i in range(m*n)])\n",
        "        \n",
        "        delta_W = tf.multiply(weight_multiplier, tf.subtract(tf.stack([x for i in range(m*n)]), self._W))\n",
        "        new_W = self._W + delta_W\n",
        "        self._W = new_W\n",
        "    \n",
        "    def fit(self, X):\n",
        "        for i in range(self._num_iterations):\n",
        "            for x in X:\n",
        "                self.training(x,i)\n",
        "        \n",
        "        centroid_grid = [[] for i in range(self._m) ]\n",
        "        self._Wts = list(self._W)\n",
        "        self._locations = list(self._topography)\n",
        "        for i, loc in enumerate(self._locations):\n",
        "            centroid_grid[loc[0]].append(self._Wts[i])\n",
        "        self._centroid_grid = centroid_grid\n",
        "        self._learned = True\n",
        "    \n",
        "    def winner(self, x):\n",
        "        idx = self.WTU_idx, self.WTU_loc\n",
        "        return idx\n",
        "    \n",
        "    def _neuron_location(self, m, n):\n",
        "        for i in range(m):\n",
        "            for j in range(n):\n",
        "                yield np.array([i,j])\n",
        "    \n",
        "    def get_centroids(self):\n",
        "        if not self._learned:\n",
        "            raise ValueError(\"SOM not trained yet\")\n",
        "        return self._centroid_grid\n",
        "    \n",
        "    def map_vects(self, X):\n",
        "        if not self._learned:\n",
        "            raise ValueError(\"SOM not trained yet\")\n",
        "\n",
        "            to_return = []\n",
        "            for vect in X:\n",
        "                min_index = min([i for i in range(len(self._Wts))], key=lambda x : np.linalg.norm(vect - self._Wts[x]))\n",
        "            \n",
        "            to_return.append(self.locations[min_index])\n",
        "\n",
        "        return to_return\n",
        "    \n",
        "def normalize(df):\n",
        "    result = df.copy()\n",
        "    for feature_name in df.columns:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    \n",
        "    return result.astype(np.float32)\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gza9NUelNumw"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"color.csv\")\n",
        "data = normalize(df[[\"R\", \"G\", \"B\"]]).values\n",
        "name = df['Color-Name'].values\n",
        "n_dim = len(df.columns) - 1\n",
        "\n",
        "colors = data\n",
        "color_names = name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUaBxtv2OygU",
        "outputId": "d24418ba-1f31-4053-ce72-b9952be924c0"
      },
      "source": [
        "som = WTU(30, 30, n_dim, 400, sigma=10.0)\n",
        "som.fit(colors)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network created with dimensions 30 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUjC4UKPKrk"
      },
      "source": [
        "image_grid = som.get_centroids()\n",
        "mapped = som.map_vects(colors)\n",
        "plt.imshow(image_grid)\n",
        "plt.title('Color Grid SOM')\n",
        "for i , m in enumerate(mapped):\n",
        "    plt.text(m[1], m[0], color_names[i], ha='center', va='center', bbox=dict(facecolor='white', alpha=0.5, lw=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}