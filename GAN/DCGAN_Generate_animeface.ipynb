{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_Generate_ani.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19CknBCViKeseui2z-iR0tV08wEnEwtbb",
      "authorship_tag": "ABX9TyMUZEQHjRDgcJS8AG/nwJxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/GAN/DCGAN_Generate_animeface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLXHaaoPehdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cb1c5e-a0af-4cb4-c4c3-a5c6f3063fbb"
      },
      "source": [
        "!pip install animeface"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting animeface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d9/40e9fdff3f9fa9dac27e1d687fc1af72efe355d040e6def6519c21e5e10a/animeface-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 15.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 7.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |█                               | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 102kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 112kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 122kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 133kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 143kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 153kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 163kB 6.2MB/s eta 0:00:01\r\u001b[K     |██                              | 174kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 184kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 194kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 204kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 215kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 225kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 235kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 245kB 6.2MB/s eta 0:00:01\r\u001b[K     |███                             | 256kB 6.2MB/s eta 0:00:01\r\u001b[K     |███                             | 266kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 276kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 286kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 296kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 307kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 317kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 327kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 337kB 6.2MB/s eta 0:00:01\r\u001b[K     |████                            | 348kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 358kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 368kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 378kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 389kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 399kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 409kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 419kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 430kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 440kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 450kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 460kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 471kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 481kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 491kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 501kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 512kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 522kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 532kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 542kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 552kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 563kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 573kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 583kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 593kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 604kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 614kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 624kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 634kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 645kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 655kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 665kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 675kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 686kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 696kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 706kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 716kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 727kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 737kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 747kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 757kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 768kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 778kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 788kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 798kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 808kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 819kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 829kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 839kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 849kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 860kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 870kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 880kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 890kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 901kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 911kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 921kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 931kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 942kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 952kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 962kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 972kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 983kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 993kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.9MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.0MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.1MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.2MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.3MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.4MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.5MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.6MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.7MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.8MB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.8MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from animeface) (7.1.2)\n",
            "Installing collected packages: animeface\n",
            "Successfully installed animeface-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVGX5D0Ee6EB"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import animeface"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q__aZ88RfBso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e57e6d-ced4-47e5-a489-80f822e5875f"
      },
      "source": [
        "anime_dir = \"\"\n",
        "cropped_dir = \"\"\n",
        "total_face_num = 0\n",
        "\n",
        "for index, filename in enumerate(glob.glob(anime_dir + \"/*.*\")):\n",
        "  try:\n",
        "    im = Image.open(filename)\n",
        "    faces = animeface.detect(im)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Exception: {}\".format(e))\n",
        "    continue\n",
        "  face_pos = faces[0].face.pos\n",
        "  coordinates = (face_pos.x, face_pos.y, face_pos.x + face_pos.width, face_pos.y + face_pos.hegith)\n",
        "\n",
        "  cropped_image = im.crop(coordinates)\n",
        "  cropped_image = cropped_image.resize((64, 64), Image.ANTIALIAS)\n",
        "  cropped_image.save(cropped_dir + \"/\" + filename + \".png\")\n",
        "  total_face_num += 1\n",
        "\n",
        "print(\"Total Face Data number : \", total_face_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception: [Errno 21] Is a directory: '/tensorflow-1.15.2'\n",
            "Total Face Data number :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I5W8jpxdFDu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models, Input, optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vkiV1lNdTog"
      },
      "source": [
        "def build_generator():\n",
        "  '''\n",
        "  input_layer = Input(shape=(latent_size,))\n",
        "  x = layers.Dense(2048)(input_layer)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Dense(256 * 8 * 8)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Activation('tanh')(x)\n",
        "  x = layers.Reshape((8, 8, 256))(x)\n",
        "  '''\n",
        "  gen_model = models.Sequential()\n",
        "  gen_model.add(layers.Dense(units=2048))\n",
        "  gen_model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  gen_model.add(layers.Dense(256 * 8 * 8))\n",
        "  gen_model.add(layers.BatchNormalization())\n",
        "  gen_model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  gen_model.add(layers.Reshape((8, 8, 256)))\n",
        "\n",
        "  gen_model.add(layers.UpSampling2D(size=(2,2)))\n",
        "\n",
        "  gen_model.add(layers.Conv2D(128, (5, 5), padding='same'))\n",
        "  gen_model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  gen_model.add(layers.UpSampling2D(size=(2,2)))\n",
        "\n",
        "  gen_model.add(layers.Conv2D(64, (5, 5), padding='same'))\n",
        "  gen_model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "  gen_model.add(layers.UpSampling2D(size=(2,2)))\n",
        "\n",
        "  gen_model.add(layers.Conv2D(3, (5, 5), padding='same'))\n",
        "  gen_model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "  return gen_model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19E_rDmnpRh"
      },
      "source": [
        "def build_discriminator():\n",
        "  \n",
        "  dis_model = models.Sequential()\n",
        "  #64 64 3\n",
        "  dis_model.add(layers.Conv2D(128, 5, padding='same', input_shape=((64, 64, 3))))\n",
        "  dis_model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  #64 64 128\n",
        "  dis_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #32 32 128\n",
        "  dis_model.add(layers.Conv2D(256, 3))\n",
        "  dis_model.add(layers.LeakyReLU(alpha=0.2))\n",
        "  #30 30 256\n",
        "  dis_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #15 15 256\n",
        "  dis_model.add(layers.Conv2D(512, 3))\n",
        "  dis_model.add(layers.LeakyReLU(0.2))\n",
        "  #13 13 512\n",
        "  dis_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  #6 6 512\n",
        "  dis_model.add(layers.Flatten())\n",
        "  #13 * 13 * 512\n",
        "  dis_model.add(layers.Dense(1024))\n",
        "  dis_model.add(layers.LeakyReLU(0.2))\n",
        "  #1024\n",
        "  dis_model.add(layers.Dense(1))\n",
        "  dis_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "  return dis_model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQkGGCybDIPq",
        "outputId": "c8f68d1e-56c2-4a0f-a861-0855cdae2cde"
      },
      "source": [
        "dataset_dir = \"dirve/MyDrive/Datasets/animeface/*.*\"\n",
        "batch_size = 128\n",
        "z_shape = 100\n",
        "epochs = 10000\n",
        "dis_learning_rate = 0.005\n",
        "gen_learning_rate = 0.005\n",
        "dis_momentum = 0.9\n",
        "gen_momentum = 0.9\n",
        "dis_nesterov = True #네스테로브 최적화기법\n",
        "gen_nesterov = True\n",
        "\n",
        "dis_optimizer = optimizers.SGD(lr=dis_learning_rate, momentum=dis_momentum, nesterov=dis_nesterov)\n",
        "gen_optimizer = optimizers.SGD(lr=gen_learning_rate, momentum=gen_momentum, nesterov=gen_nesterov)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxRTmU4BFaym"
      },
      "source": [
        "#image load\n",
        "all_images = []\n",
        "for index, filename in enumerate(glob.glob(dataset_dir)):\n",
        "    all_images.append(imread(filename, flatten=False, mode='RGB'))\n",
        "    \n",
        "X = np.array(all_images)\n",
        "X = (X - 127.5) / 127.5\n",
        "X = X.astype(np.float32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCUjwWvfFyey",
        "outputId": "13069420-4ebe-4a05-f4de-644eea7266a3"
      },
      "source": [
        "gen_model = build_generator()\n",
        "gen_model.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "dis_model = build_discriminator()\n",
        "dis_model.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "\n",
        "adversarial_model = models.Sequential()\n",
        "adversarial_model.add(gen_model)\n",
        "dis_model.trainable = False\n",
        "adversarial_model.add(dis_model)\n",
        "adversarial_model.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time.time()), write_images=True, write_grads=True, write_graph=True)\n",
        "tensorboard.set_model(gen_model)\n",
        "tensorboard.set_model(dis_model)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fMOpC9xlHMKG",
        "outputId": "52db9e3e-e7a1-4159-9d91-bf4e65ba17aa"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  print(\"Epoch \", epoch)\n",
        "  number_of_batch = int(X.shape[0] / batch_size)\n",
        "\n",
        "  dis_losses = []\n",
        "  gen_losses = []\n",
        "\n",
        "  for index in range(number_of_batch):\n",
        "\n",
        "    z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "    generated_images = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "    \"\"\"\n",
        "    Train the discriminator model\n",
        "    \"\"\"\n",
        "\n",
        "    dis_model.trainable = True\n",
        "    image_batch = X[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "    y_real = np.ones((batch_size, ), dtype=np.float32) * 0.9\n",
        "    y_fake = np.zeros((batch_size, ), dtype=np.float32) * 0.1\n",
        "\n",
        "    dis_loss_real = dis_model.train_on_batch(image_batch, y_real)\n",
        "    dis_loss_fake = dis_model.train_on_batch(generated_images, y_fake)\n",
        "\n",
        "    d_loss = (dis_loss_real+dis_loss_fake)/2\n",
        "    print(\"d_loss:\", d_loss)\n",
        "    dis_model.trainable = False\n",
        "\n",
        "\n",
        "    z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "    g_loss = adversarial_model.train_on_batch(z_noise, y_real)\n",
        "    print(\"g_loss:\", g_loss)\n",
        "\n",
        "    dis_losses.append(d_loss)\n",
        "    gen_losses.append(g_loss)\n",
        "\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "      z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "      gen_images1 = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "      for img in gen_images1[:2]:\n",
        "          save_rgb_img(img, \"drive/MyDrive/Colab Notebooks/result_data/animeface/one_{}.png\".format(epoch))\n",
        "\n",
        "  print(\"Epoch:{}, dis_loss:{}\".format(epoch, np.mean(dis_losses)))\n",
        "  print(\"Epoch:{}, gen_loss: {}\".format(epoch, np.mean(gen_losses)))\n",
        "\n",
        "  \"\"\"\n",
        "  Save losses to Tensorboard after each epoch\n",
        "  \"\"\"\n",
        "  write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
        "  write_log(tensorboard, 'generator_loss', np.mean(gen_losses), epoch)\n",
        "\n",
        "\"\"\"\n",
        "Save models\n",
        "\"\"\"\n",
        "gen_model.save(\"drive/MyDrive/Colab Notebooks/models/animeface/generator_model.h5\")\n",
        "dis_model.save(\"drive/MyDrive/Colab Notebooks/models/animeface/discriminator_model.h5\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-aaec0f6e6721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mz_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       \u001b[0mgen_images1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_images1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1914\u001b[0m       \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_batch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Yhcy7HcvtW"
      },
      "source": [
        "import glob\n",
        "import io\n",
        "import math\n",
        "import time\n",
        "\n",
        "import keras.backend as K\n",
        "import matplotlib.gridspec as gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import Sequential, Input, Model\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import ReLU\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.preprocessing import image\n",
        "from scipy.misc import imread, imsave\n",
        "from scipy.stats import entropy\n",
        "\n",
        "K.set_image_dim_ordering('tf')\n",
        "\n",
        "np.random.seed(1337)\n",
        "\n",
        "\n",
        "def build_generator():\n",
        "    gen_model = Sequential()\n",
        "\n",
        "    gen_model.add(Dense(input_dim=100, output_dim=2048))\n",
        "    gen_model.add(ReLU())\n",
        "\n",
        "    gen_model.add(Dense(256 * 8 * 8))\n",
        "    gen_model.add(BatchNormalization())\n",
        "    gen_model.add(ReLU())\n",
        "    gen_model.add(Reshape((8, 8, 256), input_shape=(256 * 8 * 8,)))\n",
        "    gen_model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "    gen_model.add(Conv2D(128, (5, 5), padding='same'))\n",
        "    gen_model.add(ReLU())\n",
        "\n",
        "    gen_model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "    gen_model.add(Conv2D(64, (5, 5), padding='same'))\n",
        "    gen_model.add(ReLU())\n",
        "\n",
        "    gen_model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "    gen_model.add(Conv2D(3, (5, 5), padding='same'))\n",
        "    gen_model.add(Activation('tanh'))\n",
        "    return gen_model\n",
        "\n",
        "\n",
        "def build_discriminator():\n",
        "    dis_model = Sequential()\n",
        "    dis_model.add(\n",
        "        Conv2D(128, (5, 5),\n",
        "               padding='same',\n",
        "               input_shape=(64, 64, 3))\n",
        "    )\n",
        "    dis_model.add(LeakyReLU(alpha=0.2))\n",
        "    dis_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    dis_model.add(Conv2D(256, (3, 3)))\n",
        "    dis_model.add(LeakyReLU(alpha=0.2))\n",
        "    dis_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    dis_model.add(Conv2D(512, (3, 3)))\n",
        "    dis_model.add(LeakyReLU(alpha=0.2))\n",
        "    dis_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    dis_model.add(Flatten())\n",
        "    dis_model.add(Dense(1024))\n",
        "    dis_model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    dis_model.add(Dense(1))\n",
        "    dis_model.add(Activation('sigmoid'))\n",
        "\n",
        "    return dis_model\n",
        "\n",
        "\n",
        "def build_adversarial_model(gen_model, dis_model):\n",
        "    model = Sequential()\n",
        "    model.add(gen_model)\n",
        "    dis_model.trainable = False\n",
        "    model.add(dis_model)\n",
        "    return model\n",
        "\n",
        "\n",
        "def write_log(callback, name, loss, batch_no):\n",
        "    \"\"\"\n",
        "    Write training summary to TensorBoard\n",
        "    \"\"\"\n",
        "    # for name, value in zip(names, logs):\n",
        "    summary = tf.Summary()\n",
        "    summary_value = summary.value.add()\n",
        "    summary_value.simple_value = loss\n",
        "    summary_value.tag = name\n",
        "    callback.writer.add_summary(summary, batch_no)\n",
        "    callback.writer.flush()\n",
        "\n",
        "\n",
        "def calculate_inception_score(images_path, batch_size=1, splits=10):\n",
        "    # Create an instance of InceptionV3\n",
        "    model = InceptionResNetV2()\n",
        "\n",
        "    images = None\n",
        "    for image_ in glob.glob(images_path):\n",
        "        # Load image\n",
        "        loaded_image = image.load_img(image_, target_size=(299, 299))\n",
        "\n",
        "        # Convert PIL image to numpy ndarray\n",
        "        loaded_image = image.img_to_array(loaded_image)\n",
        "\n",
        "        # Another another dimension (Add batch dimension)\n",
        "        loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "        # Concatenate all images into one tensor\n",
        "        if images is None:\n",
        "            images = loaded_image\n",
        "        else:\n",
        "            images = np.concatenate([images, loaded_image], axis=0)\n",
        "\n",
        "    # Calculate number of batches\n",
        "    num_batches = (images.shape[0] + batch_size - 1) // batch_size\n",
        "\n",
        "    probs = None\n",
        "\n",
        "    # Use InceptionV3 to calculate probabilities\n",
        "    for i in range(num_batches):\n",
        "        image_batch = images[i * batch_size:(i + 1) * batch_size, :, :, :]\n",
        "        prob = model.predict(preprocess_input(image_batch))\n",
        "\n",
        "        if probs is None:\n",
        "            probs = prob\n",
        "        else:\n",
        "            probs = np.concatenate([prob, probs], axis=0)\n",
        "\n",
        "    # Calculate Inception scores\n",
        "    divs = []\n",
        "    split_size = probs.shape[0] // splits\n",
        "\n",
        "    for i in range(splits):\n",
        "        prob_batch = probs[(i * split_size):((i + 1) * split_size), :]\n",
        "        p_y = np.expand_dims(np.mean(prob_batch, 0), 0)\n",
        "        div = prob_batch * (np.log(prob_batch / p_y))\n",
        "        div = np.mean(np.sum(div, 1))\n",
        "        divs.append(np.exp(div))\n",
        "\n",
        "    return np.mean(divs), np.std(divs)\n",
        "\n",
        "\n",
        "def calculate_mode_score(gen_images_path, real_images_path, batch_size=32, splits=10):\n",
        "    # Create an instance of InceptionV3\n",
        "    model = InceptionResNetV2()\n",
        "\n",
        "    # Load real images\n",
        "    real_images = None\n",
        "    for image_ in glob.glob(real_images_path):\n",
        "        # Load image\n",
        "        loaded_image = image.load_img(image_, target_size=(299, 299))\n",
        "\n",
        "        # Convert PIL image to numpy ndarray\n",
        "        loaded_image = image.img_to_array(loaded_image)\n",
        "\n",
        "        # Another another dimension (Add batch dimension)\n",
        "        loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "        # Concatenate all images into one tensor\n",
        "        if real_images is None:\n",
        "            real_images = loaded_image\n",
        "        else:\n",
        "            real_images = np.concatenate([real_images, loaded_image], axis=0)\n",
        "\n",
        "    # Load generated images\n",
        "    gen_images = None\n",
        "    for image_ in glob.glob(gen_images_path):\n",
        "        # Load image\n",
        "        loaded_image = image.load_img(image_, target_size=(299, 299))\n",
        "\n",
        "        # Convert PIL image to numpy ndarray\n",
        "        loaded_image = image.img_to_array(loaded_image)\n",
        "\n",
        "        # Another another dimension (Add batch dimension)\n",
        "        loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "        # Concatenate all images into one tensor\n",
        "        if gen_images is None:\n",
        "            gen_images = loaded_image\n",
        "        else:\n",
        "            gen_images = np.concatenate([gen_images, loaded_image], axis=0)\n",
        "\n",
        "    # Calculate number of batches for generated images\n",
        "    gen_num_batches = (gen_images.shape[0] + batch_size - 1) // batch_size\n",
        "    gen_images_probs = None\n",
        "    # Use InceptionV3 to calculate probabilities of generated images\n",
        "    for i in range(gen_num_batches):\n",
        "        image_batch = gen_images[i * batch_size:(i + 1) * batch_size, :, :, :]\n",
        "        prob = model.predict(preprocess_input(image_batch))\n",
        "\n",
        "        if gen_images_probs is None:\n",
        "            gen_images_probs = prob\n",
        "        else:\n",
        "            gen_images_probs = np.concatenate([prob, gen_images_probs], axis=0)\n",
        "\n",
        "    # Calculate number of batches for real images\n",
        "    real_num_batches = (real_images.shape[0] + batch_size - 1) // batch_size\n",
        "    real_images_probs = None\n",
        "    # Use InceptionV3 to calculate probabilities of real images\n",
        "    for i in range(real_num_batches):\n",
        "        image_batch = real_images[i * batch_size:(i + 1) * batch_size, :, :, :]\n",
        "        prob = model.predict(preprocess_input(image_batch))\n",
        "\n",
        "        if real_images_probs is None:\n",
        "            real_images_probs = prob\n",
        "        else:\n",
        "            real_images_probs = np.concatenate([prob, real_images_probs], axis=0)\n",
        "\n",
        "    # KL-Divergence: compute kl-divergence and mean of it\n",
        "    num_gen_images = len(gen_images)\n",
        "    split_scores = []\n",
        "\n",
        "    for j in range(splits):\n",
        "        gen_part = gen_images_probs[j * (num_gen_images // splits): (j + 1) * (num_gen_images // splits), :]\n",
        "        real_part = real_images_probs[j * (num_gen_images // splits): (j + 1) * (num_gen_images // splits), :]\n",
        "        gen_py = np.mean(gen_part, axis=0)\n",
        "        real_py = np.mean(real_part, axis=0)\n",
        "        scores = []\n",
        "        for i in range(gen_part.shape[0]):\n",
        "            scores.append(entropy(gen_part[i, :], gen_py))\n",
        "\n",
        "        split_scores.append(np.exp(np.mean(scores) - entropy(gen_py, real_py)))\n",
        "\n",
        "    final_mean = np.mean(split_scores)\n",
        "    final_std = np.std(split_scores)\n",
        "\n",
        "    return final_mean, final_std\n",
        "\n",
        "\n",
        "def denormalize(img):\n",
        "    img = (img + 1) * 127.5\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "\n",
        "def normalize(img):\n",
        "    return (img - 127.5) / 127.5\n",
        "\n",
        "\n",
        "def visualize_rgb(img):\n",
        "    \"\"\"\n",
        "    Visualize a rgb image\n",
        "    :param img: RGB image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_rgb_img(img, path):\n",
        "    \"\"\"\n",
        "    Save a rgb image\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"RGB Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train():\n",
        "    start_time = time.time()\n",
        "    dataset_dir = \"data/*.*\"\n",
        "    batch_size = 128\n",
        "    z_shape = 100\n",
        "    epochs = 10000\n",
        "    dis_learning_rate = 0.005\n",
        "    gen_learning_rate = 0.005\n",
        "    dis_momentum = 0.5\n",
        "    gen_momentum = 0.5\n",
        "    dis_nesterov = True\n",
        "    gen_nesterov = True\n",
        "\n",
        "    dis_optimizer = SGD(lr=dis_learning_rate, momentum=dis_momentum, nesterov=dis_nesterov)\n",
        "    gen_optimizer = SGD(lr=gen_learning_rate, momentum=gen_momentum, nesterov=gen_nesterov)\n",
        "\n",
        "    # Load images\n",
        "    all_images = []\n",
        "    for index, filename in enumerate(glob.glob(dataset_dir)):\n",
        "        all_images.append(imread(filename, flatten=False, mode='RGB'))\n",
        "\n",
        "    X = np.array(all_images)\n",
        "    X = (X - 127.5) / 127.5\n",
        "    X = X.astype(np.float32)\n",
        "\n",
        "    dis_model = build_discriminator()\n",
        "    dis_model.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "\n",
        "    gen_model = build_generator()\n",
        "    gen_model.compile(loss='mse', optimizer=gen_optimizer)\n",
        "\n",
        "    adversarial_model = build_adversarial_model(gen_model, dis_model)\n",
        "    adversarial_model.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()), write_images=True, write_grads=True, write_graph=True)\n",
        "    tensorboard.set_model(gen_model)\n",
        "    tensorboard.set_model(dis_model)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"--------------------------\")\n",
        "        print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "        dis_losses = []\n",
        "        gen_losses = []\n",
        "\n",
        "        num_batches = int(X.shape[0] / batch_size)\n",
        "\n",
        "        print(\"Number of batches:{}\".format(num_batches))\n",
        "        for index in range(num_batches):\n",
        "            print(\"Batch:{}\".format(index))\n",
        "\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "            # z_noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
        "\n",
        "            generated_images = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "            # visualize_rgb(generated_images[0])\n",
        "\n",
        "            \"\"\"\n",
        "            Train the discriminator model\n",
        "            \"\"\"\n",
        "\n",
        "            dis_model.trainable = True\n",
        "\n",
        "            image_batch = X[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "            y_real = np.ones((batch_size, )) * 0.9\n",
        "            y_fake = np.zeros((batch_size, )) * 0.1\n",
        "\n",
        "            dis_loss_real = dis_model.train_on_batch(image_batch, y_real)\n",
        "            dis_loss_fake = dis_model.train_on_batch(generated_images, y_fake)\n",
        "\n",
        "            d_loss = (dis_loss_real+dis_loss_fake)/2\n",
        "            print(\"d_loss:\", d_loss)\n",
        "\n",
        "            dis_model.trainable = False\n",
        "\n",
        "            \"\"\"\n",
        "            Train the generator model(adversarial model)\n",
        "            \"\"\"\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "            # z_noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
        "\n",
        "            g_loss = adversarial_model.train_on_batch(z_noise, y_real)\n",
        "            print(\"g_loss:\", g_loss)\n",
        "\n",
        "            dis_losses.append(d_loss)\n",
        "            gen_losses.append(g_loss)\n",
        "\n",
        "        \"\"\"\n",
        "        Sample some images and save them\n",
        "        \"\"\"\n",
        "        if epoch % 100 == 0:\n",
        "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "            gen_images1 = gen_model.predict_on_batch(z_noise)\n",
        "\n",
        "            for img in gen_images1[:2]:\n",
        "                save_rgb_img(img, \"results/one_{}.png\".format(epoch))\n",
        "\n",
        "        print(\"Epoch:{}, dis_loss:{}\".format(epoch, np.mean(dis_losses)))\n",
        "        print(\"Epoch:{}, gen_loss: {}\".format(epoch, np.mean(gen_losses)))\n",
        "\n",
        "        \"\"\"\n",
        "        Save losses to Tensorboard after each epoch\n",
        "        \"\"\"\n",
        "        write_log(tensorboard, 'discriminator_loss', np.mean(dis_losses), epoch)\n",
        "        write_log(tensorboard, 'generator_loss', np.mean(gen_losses), epoch)\n",
        "\n",
        "    \"\"\"\n",
        "    Save models\n",
        "    \"\"\"\n",
        "    gen_model.save(\"generator_model.h5\")\n",
        "    dis_model.save(\"generator_model.h5\")\n",
        "\n",
        "    print(\"Time:\", (time.time() - start_time))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}