{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age_cGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IKT8pFC-tInsJZjmS3s9ni8KMpI9l5ez",
      "authorship_tag": "ABX9TyOgCZgxImC7Q34UVgVPH3uq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/TensorflowWithKeras/blob/master/GAN/Age_cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgPQHOEAodRW"
      },
      "source": [
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras  import Input, Model, layers, optimizers, utils\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from keras_preprocessing import image\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vibFeKaioSnk"
      },
      "source": [
        "def calculate_age(taken, dob):\n",
        "  birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
        "  if birth.month < 7:\n",
        "    return taken - birth.year\n",
        "  else:\n",
        "    return taken - birth.year - 1\n",
        "\n",
        "def load_data(wiki_dir, dataset='wiki'):\n",
        "  meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
        "  full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
        "  dob = meta[dataset][0, 0][\"dob\"][0]\n",
        "  photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]\n",
        "  age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
        "  images = []\n",
        "  age_list = []\n",
        "\n",
        "  for index, image_path in enumerate(full_path):\n",
        "    images.append(image_path[0])\n",
        "    age_list.append(age[index])\n",
        "\n",
        "  return images, age_list\n",
        "\n",
        "\n",
        "#os.path.isfile(\"drive/MyDrive/Datasets/wiki_crop/wiki.mat\")\n",
        "#images, age_list = load_data(\"drive/MyDrive/wiki_crop/\", dataset='wiki')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44MVXf2Xs_Oh"
      },
      "source": [
        "def build_encoder():\n",
        "  input_layer = Input(shape=(64,64,3))\n",
        "  enc = layers.Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "  enc = layers.LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = layers.Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(enc)\n",
        "  enc = layers.BatchNormalization()(enc)\n",
        "  enc = layers.LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(enc)\n",
        "  enc = layers.BatchNormalization()(enc)\n",
        "  enc = layers.LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(enc)\n",
        "  enc = layers.BatchNormalization()(enc)\n",
        "  enc = layers.LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = layers.Flatten()(enc)\n",
        "\n",
        "  enc = layers.Dense(4096)(enc)\n",
        "  enc = layers.BatchNormalization()(enc)\n",
        "  enc = layers.LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = layers.Dense(100)(enc)\n",
        "  \n",
        "  model = Model(inputs=[input_layer], outputs=[enc])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am7dEFerD6Ze"
      },
      "source": [
        "\n",
        "def build_generator():\n",
        "  latent_dims = 100\n",
        "  num_classes = 6\n",
        "\n",
        "  input_z_noise = Input(shape=(latent_dims,))\n",
        "  input_label = Input(shape=(num_classes,))\n",
        "\n",
        "  x = layers.concatenate([input_z_noise, input_label])\n",
        "\n",
        "  x = layers.Dense(2048, input_dim=latent_dims+num_classes)(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = layers.Dense(256 * 8 * 8)(x)\n",
        "  x = layers.BatchNormalization(momentum=0.8)(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "\n",
        "  x = layers.Reshape((8, 8, 256))(x)\n",
        "\n",
        "  x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "  x = layers.Conv2D(filters=128, kernel_size=5, padding='same')(x)\n",
        "  x = layers.BatchNormalization(momentum=0.8)(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "  x = layers.Conv2D(filters=64, kernel_size=5, padding='same')(x)\n",
        "  x = layers.BatchNormalization(momentum=0.8)(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "  x = layers.Conv2D(filters=3, kernel_size=5, padding='same')(x)\n",
        "  x = layers.Activation('tanh')(x)\n",
        "\n",
        "  model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKP0R50hGE_h"
      },
      "source": [
        "def expand_label_input(x):\n",
        "  x = K.expand_dims(x, axis=1)\n",
        "  x = K.expand_dims(x, axis=1)\n",
        "  x = K.tile(x, [1, 32, 32, 1])\n",
        "  return x\n",
        "def build_discriminator():\n",
        "\n",
        "  input_shape = (64, 64, 3)\n",
        "  label_shape = (6, )\n",
        "\n",
        "  image_input = layers.Input(shape=input_shape)\n",
        "  label_input = layers.Input(shape=label_shape)\n",
        "\n",
        "  x = layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(image_input)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  label_input1 = layers.Lambda(expand_label_input)(label_input)\n",
        "  x = layers.concatenate([x, label_input1], axis=3)\n",
        "\n",
        "  x = layers.Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = layers.Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = layers.Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=[image_input, label_input], outputs=[x])\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw5xr-llqBUF"
      },
      "source": [
        "def build_fr_combined_network(encoder, generator, fr_model):\n",
        "  input_image = Input(shape=(64, 64, 3))\n",
        "  input_label = Input(shape(6, ))\n",
        "\n",
        "  latent0 = encoder(input_image)\n",
        "  gen_images = generator([latent0, input_label])\n",
        "\n",
        "  fr_model.trainable = False\n",
        "  resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=2, width_factor=2, data_format=\"channels_last\"))(gen_images)\n",
        "  embeddings = fr_model(resized_images)\n",
        "  \n",
        "  model = Model(inputs=[input_images, input_label], outputs=[embedding])\n",
        "  return model\n",
        "\n",
        "\n",
        "def build_fr_model(input_shape):\n",
        "  resent_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
        "  image_input = resent_model.input\n",
        "  x = resent_model.layers[-1].output\n",
        "  \n",
        "  out = layers.Dense(128)(x)\n",
        "  embedder_model = Model(inputs=[image_input], outputs=[out])\n",
        "\n",
        "  input_layer = Input(shape=input_shape)\n",
        "  x = embedder_model(input_layer)\n",
        "  output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
        "\n",
        "  model = Model(inputs=[input_layer], outputs=[output])\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2a6tYrltpml"
      },
      "source": [
        "def build_image_resizer():\n",
        "    input_layer = Input(shape=(64, 64, 3))\n",
        "\n",
        "    resized_images = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3,\n",
        "                                                      data_format='channels_last'))(input_layer)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[resized_images])\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awewpWxrtyQM"
      },
      "source": [
        "def euclidean_distance_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
        "\n",
        "\n",
        "def write_log(callback, name, value, batch_no):\n",
        "    pass"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n_iVzR9gsmi",
        "outputId": "9a18cd45-5325-449d-e6d5-bf536f22e8ec"
      },
      "source": [
        "data_dir = \"drive/MyDrive/Datasets/\"\n",
        "wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "image_shape = (64, 64, 3)\n",
        "z_shape = 100\n",
        "TRAIN_GAN = True\n",
        "TRAIN_ENCODER = False\n",
        "TRAIN_GAN_WITH_FR = False\n",
        "fr_image_shape = (192, 192, 3)\n",
        "\n",
        "dis_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "gen_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "adversarial_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n",
        "\n",
        "generator = build_generator()\n",
        "generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "\n",
        "discriminator.trainable = False\n",
        "input_z_noise = Input(shape=(100,))\n",
        "input_label = Input(shape=(6,))\n",
        "recons_images = generator([input_z_noise, input_label])\n",
        "valid = discriminator([recons_images, input_label])\n",
        "adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=valid)\n",
        "adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btwsfY8M6Dr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "4a957e2e-3210-4439-84d5-5c0299a4cf73"
      },
      "source": [
        "tensorboard = TensorBoard(log_dir='drive/MyDrive/Colab Notebooks/logs/{}'.format(time.time()))\n",
        "tensorboard.set_model(generator)\n",
        "tensorboard.set_model(discriminator)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ee96e3aa5f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive/MyDrive/Colab Notebooks/logs/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "622w3e8dBamf"
      },
      "source": [
        "def age_to_category(age_list):\n",
        "  age_list1 = []\n",
        "  for age in age_list:\n",
        "    if 0 < age <= 18:\n",
        "      age_category = 0\n",
        "    elif 18 < age <= 29:\n",
        "      age_category = 1\n",
        "    elif 29 < age <= 39:\n",
        "      age_category = 2\n",
        "    elif 39 < age <= 49:\n",
        "      age_category = 3\n",
        "    elif 49 < age <= 59:\n",
        "      age_category = 4\n",
        "    elif 60 < age:\n",
        "      age_category = 5\n",
        "    age_list1.append(age_category)\n",
        "\n",
        "  return age_list1\n",
        "\n",
        "images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
        "age_category = age_to_category(age_list)\n",
        "\n",
        "final_age_category = np.reshape(np.array(age_category), [len(age_category), 1])\n",
        "classes = 6\n",
        "y = utils.to_categorical(final_age_category, num_classes=classes)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q96BtHsjDPct"
      },
      "source": [
        "def load_images(data_dir, image_paths, image_shape):\n",
        "  images = None\n",
        "  for i , image_path in enumerate(image_paths):\n",
        "    if i % 100 == 0:\n",
        "      print(i)\n",
        "    if i == 1000:\n",
        "      break\n",
        "    try:\n",
        "      loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n",
        "      loaded_image = image.img_to_array(loaded_image)\n",
        "      loaded_image = np.expand_dims(loaded_image, axis=0)\n",
        "\n",
        "      if images is None:\n",
        "        images = loaded_image\n",
        "      else:\n",
        "        images = np.concatenate([images, loaded_image], axis=0)\n",
        "    except Exception as e:\n",
        "      print(\"Error: \", i, e)\n",
        "  return images\n",
        "\n",
        "#loaded_images = load_images(wiki_dir, images, (image_shape[0], image_shape[1]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whhQ58DoIxkr"
      },
      "source": [
        "def save_rgb_img(img, path):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.imshow(img)\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(\"Image\")\n",
        "  plt.savefig(path)\n",
        "  plt.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOvNnjY7pF59"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    data_dir = \"drive/MyDrive/Datasets/\"\n",
        "    wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "    epochs = 150\n",
        "    batch_size = 128\n",
        "    image_shape = (64, 64, 3)\n",
        "    z_shape = 100\n",
        "    TRAIN_GAN = True\n",
        "    TRAIN_ENCODER = False\n",
        "    TRAIN_GAN_WITH_FR = False\n",
        "    fr_image_shape = (192, 192, 3)\n",
        "\n",
        "    # Define optimizers\n",
        "    dis_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    gen_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "    adversarial_optimizer = optimizers.Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
        "\n",
        "    \"\"\"\n",
        "    Build and compile networks\n",
        "    \"\"\"\n",
        "    # Build and compile the discriminator network\n",
        "    discriminator = build_discriminator()\n",
        "    discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n",
        "\n",
        "    # Build and compile the generator network\n",
        "    generator = build_generator()\n",
        "    generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    # Build and compile the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    input_z_noise = Input(shape=(100,))\n",
        "    input_label = Input(shape=(6,))\n",
        "    recons_images = generator([input_z_noise, input_label])\n",
        "    valid = discriminator([recons_images, input_label])\n",
        "    adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n",
        "    adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n",
        "    tensorboard.set_model(generator)\n",
        "    tensorboard.set_model(discriminator)\n",
        "\n",
        "    \"\"\"\n",
        "    Load the dataset\n",
        "    \"\"\"\n",
        "    images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
        "    age_cat = age_to_category(age_list)\n",
        "    final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n",
        "    classes = len(set(age_cat))\n",
        "    y = tf.keras.utils.to_categorical(final_age_cat, num_classes=len(set(age_cat)))\n",
        "\n",
        "    loaded_images = load_images(wiki_dir, images, (image_shape[0], image_shape[1]))\n",
        "\n",
        "    # Implement label smoothing\n",
        "    real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
        "    fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
        "\n",
        "    \"\"\"\n",
        "    Train the generator and the discriminator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:{}\".format(epoch))\n",
        "\n",
        "            gen_losses = []\n",
        "            dis_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:{}\".format(index + 1))\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the discriminator network\n",
        "                \"\"\"\n",
        "\n",
        "                # Generate fake images\n",
        "                initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n",
        "                d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n",
        "\n",
        "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "                print(\"d_loss:{}\".format(d_loss))\n",
        "\n",
        "                \"\"\"\n",
        "                Train the generator network\n",
        "                \"\"\"\n",
        "\n",
        "                z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "                random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
        "                random_labels = tf.keras.utils.to_categorical(random_labels, 6)\n",
        "\n",
        "                a = tf.constant([1] * batch_size)\n",
        "                g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], a)\n",
        "\n",
        "                print(\"g_loss:{}\".format(g_loss))\n",
        "\n",
        "                gen_losses.append(g_loss)\n",
        "                dis_losses.append(d_loss)\n",
        "\n",
        "            # Write losses to Tensorboard\n",
        "            write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n",
        "            write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images after every 10th epoch\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                for i, img in enumerate(gen_images[:5]):\n",
        "                    save_rgb_img(img, path=\"results/img_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save networks\n",
        "        try:\n",
        "            generator.save_weights(\"generator.h5\")\n",
        "            discriminator.save_weights(\"discriminator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "    \"\"\"\n",
        "    Train encoder\n",
        "    \"\"\"\n",
        "\n",
        "    if TRAIN_ENCODER:\n",
        "        # Build and compile encoder\n",
        "        encoder = build_encoder()\n",
        "        encoder.compile(loss=euclidean_distance_loss, optimizer='adam')\n",
        "\n",
        "        # Load the generator network's weights\n",
        "        try:\n",
        "            generator.load_weights(\"generator.h5\")\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "        z_i = np.random.normal(0, 1, size=(5000, z_shape))\n",
        "\n",
        "        y = np.random.randint(low=0, high=6, size=(5000,), dtype=np.int64)\n",
        "        num_classes = len(set(y))\n",
        "        y = np.reshape(np.array(y), [len(y), 1])\n",
        "        y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            encoder_losses = []\n",
        "\n",
        "            number_of_batches = int(z_i.shape[0] / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                z_batch = z_i[index * batch_size:(index + 1) * batch_size]\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
        "\n",
        "                # Train the encoder model\n",
        "                encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
        "                print(\"Encoder loss:\", encoder_loss)\n",
        "\n",
        "                encoder_losses.append(encoder_loss)\n",
        "\n",
        "            # Write the encoder loss to Tensorboard\n",
        "            write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n",
        "\n",
        "        # Save the encoder model\n",
        "        encoder.save_weights(\"encoder.h5\")\n",
        "\n",
        "    \"\"\"\n",
        "    Optimize the encoder and the generator network\n",
        "    \"\"\"\n",
        "    if TRAIN_GAN_WITH_FR:\n",
        "\n",
        "        # Load the encoder network\n",
        "        encoder = build_encoder()\n",
        "        encoder.load_weights(\"encoder.h5\")\n",
        "\n",
        "        # Load the generator network\n",
        "        generator.load_weights(\"generator.h5\")\n",
        "\n",
        "        image_resizer = build_image_resizer()\n",
        "        image_resizer.compile(loss=['binary_crossentropy'], optimizer='adam')\n",
        "\n",
        "        # Face recognition model\n",
        "        fr_model = build_fr_model(input_shape=fr_image_shape)\n",
        "        fr_model.compile(loss=['binary_crossentropy'], optimizer=\"adam\")\n",
        "\n",
        "        # Make the face recognition network as non-trainable\n",
        "        fr_model.trainable = False\n",
        "\n",
        "        # Input layers\n",
        "        input_image = Input(shape=(64, 64, 3))\n",
        "        input_label = Input(shape=(6,))\n",
        "\n",
        "        # Use the encoder and the generator network\n",
        "        latent0 = encoder(input_image)\n",
        "        gen_images = generator([latent0, input_label])\n",
        "\n",
        "        # Resize images to the desired shape\n",
        "        resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=3, width_factor=3,\n",
        "                                                          data_format='channels_last'))(gen_images)\n",
        "        embeddings = fr_model(resized_images)\n",
        "\n",
        "        # Create a Keras model and specify the inputs and outputs for the network\n",
        "        fr_adversarial_model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
        "\n",
        "        # Compile the model\n",
        "        fr_adversarial_model.compile(loss=euclidean_distance_loss, optimizer=adversarial_optimizer)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "\n",
        "            reconstruction_losses = []\n",
        "\n",
        "            number_of_batches = int(len(loaded_images) / batch_size)\n",
        "            print(\"Number of batches:\", number_of_batches)\n",
        "            for index in range(number_of_batches):\n",
        "                print(\"Batch:\", index + 1)\n",
        "\n",
        "                images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "                images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
        "\n",
        "                real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
        "\n",
        "                reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n",
        "\n",
        "                print(\"Reconstruction loss:\", reconstruction_loss)\n",
        "\n",
        "                reconstruction_losses.append(reconstruction_loss)\n",
        "\n",
        "            # Write the reconstruction loss to Tensorboard\n",
        "            write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n",
        "\n",
        "            \"\"\"\n",
        "            Generate images\n",
        "            \"\"\"\n",
        "            if epoch % 10 == 0:\n",
        "                images_batch = loaded_images[0:batch_size]\n",
        "                images_batch = images_batch / 127.5 - 1.0\n",
        "                images_batch = images_batch.astype(np.float32)\n",
        "\n",
        "                y_batch = y[0:batch_size]\n",
        "                z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
        "\n",
        "                gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
        "\n",
        "                for i, img in enumerate(gen_images[:5]):\n",
        "                    save_rgb_img(img, path=\"results/img_opt_{}_{}.png\".format(epoch, i))\n",
        "\n",
        "        # Save improved weights for both of the networks\n",
        "        generator.save_weights(\"generator_optimized.h5\")\n",
        "        encoder.save_weights(\"encoder_optimized.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MavUWilAx3tJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOrmoAOnBzPp",
        "outputId": "b5fe239d-dfe0-43e3-841a-f583db6151bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}